# Еквіваріантність матриці переходу (Transition Matrix Equivariance)

Цей репозиторій містить кодову базу та результати відтворення методології побудови еквіваріантних матриць переходу. Мета проекту — продемонструвати переваги врахування симетрії даних при побудові відображень між різними просторами ознак.

## 1. Огляд Методології

Проект досліджує два підходи до побудови матриці переходу $T$ між простором вхідних ознак $A$ (Feature Model, FM) та простором цільових ознак $B$ (Metric Model, MM):

1. **Старий підхід (Baseline)**: Мінімізація середньоквадратичної помилки відтворення (MSE) без урахування симетрії:
    $$T_{old} = \arg\min_T ||B - AT||_F^2$$
2. **Новий підхід (Equivariant)**: Оптимізація з регуляризацією для забезпечення комутативності з перетвореннями симетрії (еквіваріантність):
    $$T_{new} = \arg\min_T (||B - AT||_F^2 + \lambda ||TJ_A - J_BT||_F^2)$$
    де $J_A$ та $J_B$ — генератори групи симетрії (наприклад, обертання) у відповідних просторах.

## 2. Аналіз Синтетичних Даних

Ми провели експерименти на синтетичних даних, описаних у Додатку 1.1 рукопису.

### 2.1 Вхідні Дані

Вхідні дані складаються з двох матриць ознак для 15 зразків (3 класи по 5 зразків):

- **$A \in \mathbb{R}^{15 \times 5}$**: Вхідні ознаки.
- **$B \in \mathbb{R}^{15 \times 4}$**: Цільові ознаки.

Приклад вхідних матриць (перші 5 рядків):

**Матриця A (Input Features)**:

```
[[ 2.8  -1.8  -2.8   1.3   0.4 ]
 [ 2.9  -1.9  -2.9   1.4   0.5 ]
 [ 3.0  -2.0  -3.0   1.5   0.6 ]
 [ 3.1  -2.1  -3.1   1.6   0.7 ]
 [ 3.2  -2.2  -3.2   1.7   0.8 ]]
...
```

**Матриця B (Target Features)**:

```
[[-1.979  1.959 -1.381 -1.730]
 [-1.975  1.949 -1.727 -1.761]
 [-1.844  1.998 -1.913 -1.975]
 [-1.999  2.000 -1.998 -2.000]
 [-1.999  1.999 -2.000 -1.999]]
...
```

### 2.2 Проміжні Дані (Генератори)

Для забезпечення еквіваріантності було оцінено генератори групи симетрії (обертання) $J_A$ та $J_B$ за допомогою Алгоритму 2.

**Генератор $J_A$ (5x5)**:

```
[[-59.186 -18.691 -54.368  -3.566 -26.952]
 [ 39.475   4.899  29.838 -23.401  21.809]
 [-65.622 -24.027 -63.163 -13.997 -26.655]
 [  8.999 -20.830 -14.398 -80.598  17.557]
 [ 14.877  19.610  26.445  51.197  -2.051]]
```

**Генератор $J_B$ (4x4)**:

```
[[-36.886  -9.594  44.252 -15.807]
 [ -3.209  -1.081   4.506  -0.700]
 [ 39.893   9.291 -48.086  16.415]
 [-33.429  -8.710  41.663 -14.545]]
```

### 2.3 Вихідні Дані (Результати)

Ми отримали дві матриці переходу.

**$T_{old}$ (Baseline)** - мінімізує лише похибку відтворення:

```
[[-0.759 -0.051  0.519  1.444 -0.652]
 [ 0.331  0.225 -0.356  0.513 -0.671]
 [-0.849 -0.630 -0.482 -1.053 -0.640]
 [ 0.223  0.500  0.444  0.081 -0.578]]
```

**$T_{new}$ (Equivariant)** - враховує симетрію:

```
[[-0.452 -0.124  0.640  0.879 -0.416]
 [ 0.425  0.053 -0.459 -0.170 -0.513]
 [-0.667 -0.658 -0.392 -1.334 -0.509]
 [ 0.098  0.565  0.425  0.430 -0.695]]
```

### 2.4 Порівняння Результатів

| Метрика | Старий підхід ($T_{old}$) | Новий підхід ($T_{new}$) | Коментар |
|---------|-------------------------|-------------------------|----------|
| **MSE Fidelity** | **0.0037** | 0.0052 | $T_{old}$ краще на навчальних даних (очікувано) |
| **Symmetry Defect** | 13386.54 | **0.042** | $T_{new}$ майже ідеально зберігає симетрію |
| **Robustness Error** | 0.0030 | 0.0030 | На синтетичних даних різниця незначна |

## 3. Експеримент MNIST

Для перевірки методу на реальних даних було використано датасет MNIST.

- **Модель**: CNN, навчена на класифікацію цифр.
- **Вибірка**: 1000 зображень.
- **Тест на стійкість**: Перевірка якості передбачення на зображеннях, повернутих на 30 градусів.

### Результати MNIST

| Метрика | Старий підхід | Новий підхід | Покращення |
|---------|---------------|--------------|------------|
| **Symmetry Defect** | $4.2 \times 10^8$ | $\mathbf{9.1 \times 10^4}$ | **Значне покращення** |
| **Robustness Error** | 0.662 | **0.428** | **-35.4% похибки** |
| **SSIM** | 0.257 | **0.344** | Більш структурно схожі передбачення |
| **PSNR** | 11.32 | **13.02** | Менше шуму |

> **Примітка**: На навчальних даних (без поворотів) старий підхід має меншу помилку MSE (0.153 проти 0.211), оскільки він "перенавчається" під фіксовану орієнтацію. Однак новий підхід демонструє значно кращу узагальнюючу здатність при поворотах зображень, що критично важливо для реальних застосувань.

## 4. Висновки

1. **Ефективність**: Новий метод ($T_{new}$) успішно зменшує дефект симетрії на порядки ($10^4$ разів на MNIST).
2. **Стійкість**: Експерименти на MNIST підтвердили, що врахування еквіваріантності робить модель значно стійкішою до геометричних трансформацій (зменшення похибки на повернутих даних на 35%).
3. **Компроміс**: Існує невеликий компроміс у точності відтворення на навчальних даних (trade-off), але виграш у робастності виправдовує це для задач, де важлива інваріантність до поворотів.

Згенеровані дані та результати знаходяться у директоріях `data/` та `outputs/`.
